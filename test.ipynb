{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943f330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn import model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675fc067",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './data/train.csv'\n",
    "test_file = './data/test.csv'\n",
    "trainDF = pd.read_csv(train_file)\n",
    "testDF = pd.read_csv(test_file)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b99f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExperiment(trainInput, trainOutput, predictors, alg= LinearRegression()):\n",
    "    cvMeanScore = model_selection.cross_val_score(alg, trainInput.loc[:, predictors], trainOutput, cv=10, scoring='r2', n_jobs=-1).mean()\n",
    "    return cvMeanScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f365bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doKaggleTest(trainInput, testInput, trainOutput, testIDs, predictors):\n",
    "    alg = LinearRegression()\n",
    "\n",
    "    # Train the algorithm using all the training data\n",
    "    alg.fit(trainInput.loc[:, predictors], trainOutput)\n",
    "\n",
    "    # Make predictions on the test set.\n",
    "    predictions = alg.predict(testInput.loc[:, predictors])\n",
    "\n",
    "    # Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "    submission = pd.DataFrame({\n",
    "        \"Id\": testIDs,\n",
    "        \"SalePrice\": predictions\n",
    "    })\n",
    "\n",
    "    # Prepare CSV\n",
    "    submission.to_csv('data/testResults.csv', index=False)\n",
    "    # Now, this .csv file can be uploaded to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7157c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/Users/moon/Downloads/test.txt'\n",
    "# ls = []\n",
    "# with open(path, 'r') as f:\n",
    "#     for line in f:\n",
    "#         data = line.split(' ')\n",
    "#         if data[0] != 'def':\n",
    "#             continue\n",
    "#         a = line.replace('def ', '')\n",
    "#         call1 = a.replace('targetDF', 'trainDF').replace('sourceDF', 'originalTrainDF').replace(':', '')\n",
    "#         call2 = a.replace('targetDF', 'testDF').replace('sourceDF', 'originalTrainDF').replace(':', '')\n",
    "#         ls.append(call1)\n",
    "#         ls.append(call2)\n",
    "#         ls.append('\\n')\n",
    "# s = '\\n'.join(ls)\n",
    "# print(s, sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d50724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(trainDF, testDF):\n",
    "    predictors = ['1stFlrSF', '2ndFlrSF', 'YearBuilt']\n",
    "    \n",
    "    originalTrainDF = trainDF.copy()\n",
    "    preprocessAllColumns(trainDF, originalTrainDF)\n",
    "    preprocessAllColumns(testDF, originalTrainDF)\n",
    "    deletePoints(trainDF)\n",
    "#     print(trainDF.head())\n",
    "#     print(testDF.head())\n",
    "    \n",
    "    trainInput = trainDF.loc[:, predictors]\n",
    "    testInput = testDF.loc[:, predictors]\n",
    "    \n",
    "    trainOutput = trainDF.loc[:, 'SalePrice']\n",
    "    testIDs = testDF.loc[:, 'Id']\n",
    "    \n",
    "    return trainInput, testInput, trainOutput, testIDs, predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0602e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessAllColumns(targetDF, sourceDF):\n",
    "    preMSSubClass(targetDF, sourceDF)\n",
    "    preMSZoning(targetDF, sourceDF)\n",
    "    preLotFrontage(targetDF, sourceDF)\n",
    "    preStreet(targetDF, sourceDF)\n",
    "    preLotShape(targetDF, sourceDF)\n",
    "    preLandContour(targetDF, sourceDF)\n",
    "    preUtilities(targetDF, sourceDF)\n",
    "    preLotConfit(targetDF, sourceDF)\n",
    "    preLandSlope(targetDF, sourceDF)\n",
    "    preNeighborhood(targetDF, sourceDF)\n",
    "    preConditions(targetDF, sourceDF)\n",
    "    preBldgType(targetDF, sourceDF)\n",
    "    preHouseStyle(targetDF, sourceDF)\n",
    "    preRoofStyle(targetDF, sourceDF)\n",
    "    preYearBuilt(targetDF, sourceDF)\n",
    "    preRoofMatl(targetDF, sourceDF)\n",
    "    preExteriors(targetDF, sourceDF)\n",
    "    preMasVnrType(targetDF, sourceDF)\n",
    "    preMasVnrArea(targetDF, sourceDF)\n",
    "    preExterQual(targetDF, sourceDF)\n",
    "    preExterCond(targetDF, sourceDF)\n",
    "    preFoundation(targetDF, sourceDF)\n",
    "    preBsmtQual(targetDF, sourceDF)\n",
    "    preBsmtCond(targetDF, sourceDF)\n",
    "    preBsmtExposure(targetDF, sourceDF)\n",
    "    preBsmtFinType1(targetDF, sourceDF)\n",
    "    preBsmtFinType2(targetDF, sourceDF)\n",
    "    preBsmtFinSFs(targetDF, sourceDF)\n",
    "    preHeatingQC(targetDF, sourceDF)\n",
    "    preCentralAir(targetDF, sourceDF)\n",
    "    preElectrical(targetDF, sourceDF)\n",
    "    preKitchenQual(targetDF, sourceDF)\n",
    "    preFunctional(targetDF, sourceDF)\n",
    "    preFireplaceQu(targetDF, sourceDF)\n",
    "    preGarageType(targetDF, sourceDF)\n",
    "    preGarageYrBlt(targetDF, sourceDF)\n",
    "    preGarageFinish(targetDF, sourceDF)\n",
    "    preGarageQual(targetDF, sourceDF)\n",
    "    preGarageCond(targetDF, sourceDF)\n",
    "    prePavedDrive(targetDF, sourceDF)\n",
    "    prePoolQC(targetDF, sourceDF)\n",
    "    preFence(targetDF, sourceDF)\n",
    "    preSaleType(targetDF, sourceDF)\n",
    "    preSaleCondition(targetDF, sourceDF)\n",
    "    \n",
    "    preDropColumns(targetDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9112d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preMSSubClass(targetDF, sourceDF):\n",
    "    newDF = pd.get_dummies(targetDF, columns=['MSSubClass'])\n",
    "    newColumns = list(set(newDF.columns) - set(targetDF.columns))\n",
    "    targetDF.loc[:, newColumns] = newDF.loc[:, newColumns]\n",
    "\n",
    "    \n",
    "def preMSZoning(targetDF, sourceDF):\n",
    "    newDF = pd.get_dummies(targetDF, columns=['MSZoning'])\n",
    "    newColumns = list(set(newDF.columns) - set(targetDF.columns))\n",
    "    targetDF.loc[:, newColumns] = newDF.loc[:, newColumns]\n",
    "\n",
    "    \n",
    "def preLotFrontage(targetDF, sourceDF):\n",
    "    # replace nan with numbers\n",
    "    targetDF.loc[:, 'LotFrontage'] = targetDF.loc[:, 'LotFrontage'].fillna(sourceDF.loc[:, 'LotFrontage'].median())\n",
    "    \n",
    "    \n",
    "def preStreet(targetDF, sourceDF):\n",
    "    # create two indicator variables\n",
    "    targetDF.loc[:, 'Street_Grvl'] = targetDF.loc[:, 'Street'].map(lambda v: 1 if v=='Grvl' else 0)\n",
    "    targetDF.loc[:, 'Street_Pave'] = targetDF.loc[:, 'Street'].map(lambda v: 1 if v=='Pave' else 0)\n",
    "    \n",
    "\n",
    "def preLotShape(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'LotShape'] = targetDF.loc[:, 'LotShape'].map(lambda v: 3 if v=='Reg' else v)\n",
    "    targetDF.loc[:, 'LotShape'] = targetDF.loc[:, 'LotShape'].map(lambda v: 2 if v=='IR1' else v)\n",
    "    targetDF.loc[:, 'LotShape'] = targetDF.loc[:, 'LotShape'].map(lambda v: 1 if v=='IR2' else v)\n",
    "    targetDF.loc[:, 'LotShape'] = targetDF.loc[:, 'LotShape'].map(lambda v: 0 if v=='IR3' else v)\n",
    "    assert targetDF.loc[:, 'LotShape'].map(np.isreal).all()\n",
    "    \n",
    "    \n",
    "def preLandContour(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'LandContour'] = targetDF.loc[:, 'LandContour'].map(lambda v: 3 if v=='Lvl' else v)\n",
    "    targetDF.loc[:, 'LandContour'] = targetDF.loc[:, 'LandContour'].map(lambda v: 2 if v=='Bnk' else v)\n",
    "    targetDF.loc[:, 'LandContour'] = targetDF.loc[:, 'LandContour'].map(lambda v: 1 if v=='HLS' else v)\n",
    "    targetDF.loc[:, 'LandContour'] = targetDF.loc[:, 'LandContour'].map(lambda v: 0 if v=='Low' else v)\n",
    "    assert targetDF.loc[:, 'LandContour'].map(np.isreal).all()\n",
    "    \n",
    "    \n",
    "def preUtilities(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'Utilities'] = targetDF.loc[:, 'Utilities'].map(lambda v: 3 if v=='AllPub' else v)\n",
    "    targetDF.loc[:, 'Utilities'] = targetDF.loc[:, 'Utilities'].map(lambda v: 2 if v=='NoSewr' else v)\n",
    "    targetDF.loc[:, 'Utilities'] = targetDF.loc[:, 'Utilities'].map(lambda v: 1 if v=='NoSeWa' else v)\n",
    "    targetDF.loc[:, 'Utilities'] = targetDF.loc[:, 'Utilities'].map(lambda v: 0 if v=='ELO' else v)\n",
    "    assert targetDF.loc[:, 'Utilities'].map(np.isreal).all()\n",
    "    \n",
    "    \n",
    "def preLotConfit(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preLandSlope(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'LandSlope'] = targetDF.loc[:, 'LandSlope'].map(lambda v: 2 if v=='Gtl' else v)\n",
    "    targetDF.loc[:, 'LandSlope'] = targetDF.loc[:, 'LandSlope'].map(lambda v: 1 if v=='Mod' else v)\n",
    "    targetDF.loc[:, 'LandSlope'] = targetDF.loc[:, 'LandSlope'].map(lambda v: 0 if v=='Sev' else v)\n",
    "    assert targetDF.loc[:, 'LandSlope'].map(np.isreal).all()\n",
    "    \n",
    "\n",
    "def preNeighborhood(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preConditions(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'NoisyArea'] = targetDF.loc[:, 'Condition1'].map(lambda v: 1 if v!=\"Norm\" else 0)\n",
    "    \n",
    "\n",
    "def preBldgType(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preHouseStyle(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'HouseStyle'] = targetDF.loc[:, 'HouseStyle'].map(lambda v: 1 if v=='1Story' else v)\n",
    "    targetDF.loc[:, 'HouseStyle'] = targetDF.loc[:, 'HouseStyle'].map(lambda v: 2 if v=='1.5Fin' else v)\n",
    "    targetDF.loc[:, 'HouseStyle'] = targetDF.loc[:, 'HouseStyle'].map(lambda v: 1.5 if v=='1.5Unf' else v)\n",
    "    targetDF.loc[:, 'HouseStyle'] = targetDF.loc[:, 'HouseStyle'].map(lambda v: 3 if v=='2Story' else v)\n",
    "    targetDF.loc[:, 'HouseStyle'] = targetDF.loc[:, 'HouseStyle'].map(lambda v: 4 if v=='2.5Fin' else v)\n",
    "    targetDF.loc[:, 'HouseStyle'] = targetDF.loc[:, 'HouseStyle'].map(lambda v: 3.5 if v=='2.5Unf' else v)\n",
    "    targetDF.loc[:, 'HouseStyle'] = targetDF.loc[:, 'HouseStyle'].map(lambda v: 2 if v=='SFoyer' else v)\n",
    "    targetDF.loc[:, 'HouseStyle'] = targetDF.loc[:, 'HouseStyle'].map(lambda v: 2 if v=='SLvl' else v)\n",
    "    assert targetDF.loc[:, 'HouseStyle'].map(np.isreal).all()\n",
    "\n",
    "    \n",
    "def preYearBuilt(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'YearsOld'] = diffFromMax(targetDF, sourceDF, 'YearBuilt')\n",
    "    \n",
    "    \n",
    "def preRoofStyle(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preRoofMatl(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preExteriors(targetDF, sourceDF):\n",
    "    targetDF = pd.get_dummies(targetDF, 'Exterior1st')\n",
    "\n",
    "\n",
    "def preMasVnrType(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preMasVnrArea(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'MasVnrArea'] = targetDF.loc[:, 'MasVnrArea'].fillna(sourceDF.loc[:, 'MasVnrArea'].median())\n",
    "\n",
    "\n",
    "def preExterQual(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'ExterQual'] = targetDF.loc[:, 'ExterQual'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'ExterQual'] = targetDF.loc[:, 'ExterQual'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'ExterQual'] = targetDF.loc[:, 'ExterQual'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'ExterQual'] = targetDF.loc[:, 'ExterQual'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'ExterQual'] = targetDF.loc[:, 'ExterQual'].map(lambda v: 0 if v=='Po' else v)\n",
    "    assert targetDF.loc[:, 'ExterQual'].map(np.isreal).all() \n",
    "\n",
    "    \n",
    "def preExterCond(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'ExterCond'] = targetDF.loc[:, 'ExterCond'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'ExterCond'] = targetDF.loc[:, 'ExterCond'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'ExterCond'] = targetDF.loc[:, 'ExterCond'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'ExterCond'] = targetDF.loc[:, 'ExterCond'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'ExterCond'] = targetDF.loc[:, 'ExterCond'].map(lambda v: 0 if v=='Po' else v)\n",
    "    assert targetDF.loc[:, 'ExterCond'].map(np.isreal).all()\n",
    "\n",
    "    \n",
    "def preFoundation(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preBsmtQual(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'BsmtQual'] = targetDF.loc[:, 'BsmtQual'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'BsmtQual'] = targetDF.loc[:, 'BsmtQual'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'BsmtQual'] = targetDF.loc[:, 'BsmtQual'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'BsmtQual'] = targetDF.loc[:, 'BsmtQual'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'BsmtQual'] = targetDF.loc[:, 'BsmtQual'].map(lambda v: 0 if v=='Po' else v)\n",
    "    targetDF.loc[:, 'BsmtQual'] = targetDF.loc[:, 'BsmtQual'].fillna(0)\n",
    "    assert targetDF.loc[:, 'BsmtQual'].map(np.isreal).all() \n",
    "\n",
    "\n",
    "def preBsmtCond(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'BsmtCond'] = targetDF.loc[:, 'BsmtCond'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'BsmtCond'] = targetDF.loc[:, 'BsmtCond'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'BsmtCond'] = targetDF.loc[:, 'BsmtCond'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'BsmtCond'] = targetDF.loc[:, 'BsmtCond'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'BsmtCond'] = targetDF.loc[:, 'BsmtCond'].map(lambda v: 0 if v=='Po' else v)\n",
    "    targetDF.loc[:, 'BsmtCond'] = targetDF.loc[:, 'BsmtCond'].fillna(0)\n",
    "    assert targetDF.loc[:, 'BsmtCond'].map(np.isreal).all()\n",
    "    \n",
    "\n",
    "def preBsmtExposure(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'BsmtExposure'] = targetDF.loc[:, 'BsmtExposure'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'BsmtExposure'] = targetDF.loc[:, 'BsmtExposure'].map(lambda v: 2 if v=='Av' else v)\n",
    "    targetDF.loc[:, 'BsmtExposure'] = targetDF.loc[:, 'BsmtExposure'].map(lambda v: 1 if v=='Mn' else v)\n",
    "    targetDF.loc[:, 'BsmtExposure'] = targetDF.loc[:, 'BsmtExposure'].map(lambda v: 0 if v=='No' else v)\n",
    "    targetDF.loc[:, 'BsmtExposure'] = targetDF.loc[:, 'BsmtExposure'].fillna(0)\n",
    "    assert targetDF.loc[:, 'BsmtExposure'].map(np.isreal).all() \n",
    "    \n",
    "\n",
    "def preBsmtFinType1(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'BsmtFinType1'] = targetDF.loc[:, 'BsmtFinType1'].map(lambda v: 5 if v=='GLQ' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType1'] = targetDF.loc[:, 'BsmtFinType1'].map(lambda v: 4 if v=='ALQ' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType1'] = targetDF.loc[:, 'BsmtFinType1'].map(lambda v: 3 if v=='BLQ' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType1'] = targetDF.loc[:, 'BsmtFinType1'].map(lambda v: 2 if v=='Rec' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType1'] = targetDF.loc[:, 'BsmtFinType1'].map(lambda v: 1 if v=='LwQ' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType1'] = targetDF.loc[:, 'BsmtFinType1'].map(lambda v: 0 if v=='Unf' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType1'] = targetDF.loc[:, 'BsmtFinType1'].fillna(0)\n",
    "    assert targetDF.loc[:, 'BsmtFinType1'].map(np.isreal).all() \n",
    "\n",
    "\n",
    "def preBsmtFinType2(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'BsmtFinType2'] = targetDF.loc[:, 'BsmtFinType2'].map(lambda v: 5 if v=='GLQ' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType2'] = targetDF.loc[:, 'BsmtFinType2'].map(lambda v: 4 if v=='ALQ' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType2'] = targetDF.loc[:, 'BsmtFinType2'].map(lambda v: 3 if v=='BLQ' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType2'] = targetDF.loc[:, 'BsmtFinType2'].map(lambda v: 2 if v=='Rec' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType2'] = targetDF.loc[:, 'BsmtFinType2'].map(lambda v: 1 if v=='LwQ' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType2'] = targetDF.loc[:, 'BsmtFinType2'].map(lambda v: 0 if v=='Unf' else v)\n",
    "    targetDF.loc[:, 'BsmtFinType2'] = targetDF.loc[:, 'BsmtFinType2'].fillna(0)\n",
    "    assert targetDF.loc[:, 'BsmtFinType2'].map(np.isreal).all() \n",
    "\n",
    "\n",
    "def preBsmtFinSFs(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'BsmtFinSFSum'] = targetDF.loc[:, 'BsmtFinSF1'] + targetDF.loc[:, 'BsmtFinSF2']\n",
    "    \n",
    "\n",
    "def preHeatingQC(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'HeatingQC'] = targetDF.loc[:, 'HeatingQC'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'HeatingQC'] = targetDF.loc[:, 'HeatingQC'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'HeatingQC'] = targetDF.loc[:, 'HeatingQC'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'HeatingQC'] = targetDF.loc[:, 'HeatingQC'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'HeatingQC'] = targetDF.loc[:, 'HeatingQC'].map(lambda v: 0 if v=='Po' else v)\n",
    "    assert targetDF.loc[:, 'HeatingQC'].map(np.isreal).all() \n",
    "\n",
    "\n",
    "def preCentralAir(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'CentralAir'] = targetDF.loc[:, 'CentralAir'].map(lambda v: 1 if v=='Y' else v)\n",
    "    targetDF.loc[:, 'CentralAir'] = targetDF.loc[:, 'CentralAir'].map(lambda v: 0 if v=='N' else v)\n",
    "    assert targetDF.loc[:, 'CentralAir'].map(np.isreal).all() \n",
    "    \n",
    "\n",
    "def preElectrical(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'Electrical'] = targetDF.loc[:, 'Electrical'].map(lambda v: 3 if v=='SBrkr' else v)\n",
    "    targetDF.loc[:, 'Electrical'] = targetDF.loc[:, 'Electrical'].map(lambda v: 2 if v=='FuseA' else v)\n",
    "    targetDF.loc[:, 'Electrical'] = targetDF.loc[:, 'Electrical'].map(lambda v: 1 if v=='FuseF' else v)\n",
    "    targetDF.loc[:, 'Electrical'] = targetDF.loc[:, 'Electrical'].map(lambda v: 0 if v=='FuseP' else v)\n",
    "    targetDF.loc[:, 'Electrical'] = targetDF.loc[:, 'Electrical'].map(lambda v: 0 if v=='Mix' else v)\n",
    "\n",
    "    \n",
    "def preKitchenQual(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'KitchenQual'] = targetDF.loc[:, 'KitchenQual'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'KitchenQual'] = targetDF.loc[:, 'KitchenQual'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'KitchenQual'] = targetDF.loc[:, 'KitchenQual'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'KitchenQual'] = targetDF.loc[:, 'KitchenQual'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'KitchenQual'] = targetDF.loc[:, 'KitchenQual'].map(lambda v: 0 if v=='Po' else v)\n",
    "    assert targetDF.loc[:, 'KitchenQual'].map(np.isreal).all() \n",
    "    \n",
    "    \n",
    "def preFunctional(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'Functional'] = targetDF.loc[:, 'Functional'].map(lambda v: 7 if v=='Sal' else v)\n",
    "    targetDF.loc[:, 'Functional'] = targetDF.loc[:, 'Functional'].map(lambda v: 6 if v=='Sev' else v)\n",
    "    targetDF.loc[:, 'Functional'] = targetDF.loc[:, 'Functional'].map(lambda v: 5 if v=='Maj2' else v)\n",
    "    targetDF.loc[:, 'Functional'] = targetDF.loc[:, 'Functional'].map(lambda v: 4 if v=='Maj1' else v)\n",
    "    targetDF.loc[:, 'Functional'] = targetDF.loc[:, 'Functional'].map(lambda v: 3 if v=='Mod' else v)\n",
    "    targetDF.loc[:, 'Functional'] = targetDF.loc[:, 'Functional'].map(lambda v: 2 if v=='Min2' else v)\n",
    "    targetDF.loc[:, 'Functional'] = targetDF.loc[:, 'Functional'].map(lambda v: 1 if v=='Min1' else v)\n",
    "    targetDF.loc[:, 'Functional'] = targetDF.loc[:, 'Functional'].map(lambda v: 0 if v=='Typ' else v)\n",
    "    assert targetDF.loc[:, 'Functional'].map(np.isreal).all() \n",
    "\n",
    "def preFireplaceQu(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'FireplaceQu'] = targetDF.loc[:, 'FireplaceQu'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'FireplaceQu'] = targetDF.loc[:, 'FireplaceQu'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'FireplaceQu'] = targetDF.loc[:, 'FireplaceQu'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'FireplaceQu'] = targetDF.loc[:, 'FireplaceQu'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'FireplaceQu'] = targetDF.loc[:, 'FireplaceQu'].map(lambda v: 0 if v=='Po' else v)\n",
    "    targetDF.loc[:, 'FireplaceQu'] = targetDF.loc[:, 'FireplaceQu'].fillna(0)\n",
    "    assert targetDF.loc[:, 'FireplaceQu'].map(np.isreal).all() \n",
    "\n",
    "\n",
    "def preGarageYrBlt(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'GarageYrBlt'] = targetDF.loc[:, 'GarageYrBlt'].fillna(sourceDF.loc[:, 'GarageYrBlt'].median())\n",
    "    \n",
    "    \n",
    "def preGarageType(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preGarageFinish(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'GarageFinish'] = targetDF.loc[:, 'GarageFinish'].map(lambda v: 2 if v=='Fin' else v)\n",
    "    targetDF.loc[:, 'GarageFinish'] = targetDF.loc[:, 'GarageFinish'].map(lambda v: 1 if v=='RFn' else v)\n",
    "    targetDF.loc[:, 'GarageFinish'] = targetDF.loc[:, 'GarageFinish'].map(lambda v: 0 if v=='Unf' else v)\n",
    "    targetDF.loc[:, 'GarageFinish'] = targetDF.loc[:, 'GarageFinish'].fillna(0)\n",
    "    assert targetDF.loc[:, 'GarageFinish'].map(np.isreal).all() \n",
    "    \n",
    "    \n",
    "def preGarageQual(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'GarageQual'] = targetDF.loc[:, 'GarageQual'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'GarageQual'] = targetDF.loc[:, 'GarageQual'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'GarageQual'] = targetDF.loc[:, 'GarageQual'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'GarageQual'] = targetDF.loc[:, 'GarageQual'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'GarageQual'] = targetDF.loc[:, 'GarageQual'].map(lambda v: 0 if v=='Po' else v)\n",
    "    targetDF.loc[:, 'GarageQual'] = targetDF.loc[:, 'GarageQual'].fillna(0)\n",
    "    assert targetDF.loc[:, 'GarageQual'].map(np.isreal).all() \n",
    "    \n",
    "\n",
    "def preGarageCond(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'GarageCond'] = targetDF.loc[:, 'GarageCond'].map(lambda v: 4 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'GarageCond'] = targetDF.loc[:, 'GarageCond'].map(lambda v: 3 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'GarageCond'] = targetDF.loc[:, 'GarageCond'].map(lambda v: 2 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'GarageCond'] = targetDF.loc[:, 'GarageCond'].map(lambda v: 1 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'GarageCond'] = targetDF.loc[:, 'GarageCond'].map(lambda v: 0 if v=='Po' else v)\n",
    "    targetDF.loc[:, 'GarageCond'] = targetDF.loc[:, 'GarageCond'].fillna(0)\n",
    "    assert targetDF.loc[:, 'GarageCond'].map(np.isreal).all() \n",
    "    \n",
    "\n",
    "def prePavedDrive(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'PavedDrive'] = targetDF.loc[:, 'PavedDrive'].map(lambda v: 2 if v=='Y' else v)\n",
    "    targetDF.loc[:, 'PavedDrive'] = targetDF.loc[:, 'PavedDrive'].map(lambda v: 1 if v=='P' else v)\n",
    "    targetDF.loc[:, 'PavedDrive'] = targetDF.loc[:, 'PavedDrive'].map(lambda v: 0 if v=='N' else v)\n",
    "    assert targetDF.loc[:, 'PavedDrive'].map(np.isreal).all() \n",
    "    \n",
    "    \n",
    "def prePoolQC(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'PoolQC'] = targetDF.loc[:, 'PoolQC'].map(lambda v: 3 if v=='Ex' else v)\n",
    "    targetDF.loc[:, 'PoolQC'] = targetDF.loc[:, 'PoolQC'].map(lambda v: 2 if v=='Gd' else v)\n",
    "    targetDF.loc[:, 'PoolQC'] = targetDF.loc[:, 'PoolQC'].map(lambda v: 1 if v=='TA' else v)\n",
    "    targetDF.loc[:, 'PoolQC'] = targetDF.loc[:, 'PoolQC'].map(lambda v: 0 if v=='Fa' else v)\n",
    "    targetDF.loc[:, 'PoolQC'] = targetDF.loc[:, 'PoolQC'].fillna(0)\n",
    "    assert targetDF.loc[:, 'GarageCond'].map(np.isreal).all() \n",
    "\n",
    "\n",
    "def preFence(targetDF, sourceDF):\n",
    "    targetDF.loc[:, 'Fence'] = targetDF.loc[:, 'Fence'].map(lambda v: 3 if v=='GdPrv' else v)\n",
    "    targetDF.loc[:, 'Fence'] = targetDF.loc[:, 'Fence'].map(lambda v: 2 if v=='MnPrv' else v)\n",
    "    targetDF.loc[:, 'Fence'] = targetDF.loc[:, 'Fence'].map(lambda v: 1 if v=='GdWo' else v)\n",
    "    targetDF.loc[:, 'Fence'] = targetDF.loc[:, 'Fence'].map(lambda v: 0 if v=='MnWw' else v)\n",
    "    targetDF.loc[:, 'Fence'] = targetDF.loc[:, 'Fence'].fillna(0)\n",
    "    assert targetDF.loc[:, 'Fence'].map(np.isreal).all() \n",
    "\n",
    "\n",
    "def preSaleType(targetDF, sourceDF):\n",
    "    pass\n",
    "\n",
    "\n",
    "def preSaleCondition(targetDF, sourceDF):\n",
    "    newDF = pd.get_dummies(targetDF, columns=['SaleCondition'])\n",
    "    newColumns = list(set(newDF.columns) - set(targetDF.columns))\n",
    "    targetDF.loc[:, newColumns] = newDF.loc[:, newColumns]\n",
    "    \n",
    "\n",
    "def preDropColumns(targetDF):\n",
    "    replaced_cols = ['MSZoning', 'YearBuilt','SaleCondition']\n",
    "    missing_cols = ['Alley', 'PoolQC', 'MiscFeature', 'FireplaceQu', 'LotFrontage']\n",
    "    drop_cols = replaced_cols + missing_cols\n",
    "    targetDF.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7561cb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletePoints(df):\n",
    "    # Delete an obs with Electrical missing\n",
    "    df.drop(df.loc[df.loc[:, 'Electrical'].isna()].index, inplace=True)\n",
    "    # Delete two outliers in terms of GrLivArea \n",
    "    GrLivArea_outliers = df.sort_values(by = 'GrLivArea', ascending = False)[:2].index\n",
    "    df = df.drop(GrLivArea_outliers, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc52512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(targetDF, sourceDF, cols=None):\n",
    "    if cols:\n",
    "        mean = sourceDF.loc[:, cols].mean()\n",
    "        std = sourceDF.loc[:, cols].std()\n",
    "        standardizedDF = (targetDF.loc[:, cols] - mean)/std\n",
    "    else:\n",
    "        mean = sourceDF.loc[:, :].mean()\n",
    "        std = sourceDF.loc[:, :].std()\n",
    "        standardizedDF = (targetDF.loc[:, :] - mean)/std\n",
    "    return standardizedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b52a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffFromMax(targetDF, sourceDF, cols):\n",
    "    maxVal = sourceDF.loc[:, cols].max()\n",
    "    diffFromMaxDF = -(targetDF.loc[:, cols] - maxVal)\n",
    "    return diffFromMaxDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7b53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrateHelpers(trainDF):\n",
    "    print(\"Attributes with missing values:\", getAttrsWithMissingValues(trainDF), sep='\\n')\n",
    "    \n",
    "    numericAttrs = getNumericAttrs(trainDF)\n",
    "    print(\"Numeric attributes:\", numericAttrs, sep='\\n')\n",
    "    \n",
    "    nonnumericAttrs = getNonNumericAttrs(trainDF)\n",
    "    print(\"Non-numeric attributes:\", nonnumericAttrs, sep='\\n')\n",
    "\n",
    "    print(\"Values, for each non-numeric attribute:\", getAttrToValuesDictionary(trainDF.loc[:, nonnumericAttrs]), sep='\\n')\n",
    "\n",
    "# ===============================================================================\n",
    "'''\n",
    "Returns a dictionary mapping an attribute to the array of values for that attribute.\n",
    "'''\n",
    "def getAttrToValuesDictionary(df):\n",
    "    attrToValues = {}\n",
    "    for attr in df.columns.values:\n",
    "        attrToValues[attr] = df.loc[:, attr].unique()\n",
    "\n",
    "    return attrToValues\n",
    "\n",
    "# ===============================================================================\n",
    "'''\n",
    "Returns the attributes with missing values.\n",
    "'''\n",
    "def getAttrsWithMissingValues(df):\n",
    "    valueCountSeries = df.count(axis=0)  # 0 to count down the rows\n",
    "    numCases = df.shape[0]  # Number of examples - number of rows in the data frame\n",
    "    missingSeries = (numCases - valueCountSeries)  # A Series showing the number of missing values, for each attribute\n",
    "    attrsWithMissingValues = missingSeries[missingSeries != 0].index\n",
    "    return attrsWithMissingValues\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "'''\n",
    "Returns the numeric attributes.\n",
    "'''\n",
    "def getNumericAttrs(df):\n",
    "    return __getNumericHelper(df, True)\n",
    "\n",
    "'''\n",
    "Returns the non-numeric attributes.\n",
    "'''\n",
    "def getNonNumericAttrs(df):\n",
    "    return __getNumericHelper(df, False)\n",
    "\n",
    "def __getNumericHelper(df, findNumeric):\n",
    "    isNumeric = df.applymap(np.isreal) # np.isreal is a function that takes a value and returns True (the value is real) or False\n",
    "                                       # applymap applies the given function to the whole data frame\n",
    "                                       # So this returns a DataFrame of True/False values indicating for each value in the original DataFrame whether it is real (numeric) or not\n",
    "\n",
    "    isNumeric = isNumeric.all() # all: For each column, returns whether all elements are True\n",
    "    attrs = isNumeric.loc[isNumeric==findNumeric].index # selects the values in isNumeric that are <findNumeric> (True or False)\n",
    "    return attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d67d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Read the original data files\n",
    "    trainDF = pd.read_csv(\"data/train.csv\")\n",
    "    testDF = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "#     demonstrateHelpers(trainDF)\n",
    "\n",
    "    trainInput, testInput, trainOutput, testIDs, predictors = transformData(trainDF, testDF)\n",
    "    cvMeanScore = doExperiment(trainInput, trainOutput, predictors)\n",
    "    print(\"CV Average Score:\", cvMeanScore)    \n",
    "#     doKaggleTest(trainInput, testInput, trainOutput, testIDs, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95382a42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d0806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardSelection():\n",
    "    trainDF = pd.read_csv(\"data/train.csv\")\n",
    "#     trainDF = trainDF.loc[trainDF.loc[:, 'SalePrice'] > 339806]\n",
    "#     testDF = pd.read_csv(\"data/test.csv\")\n",
    "    originalTrainDf = trainDF.copy()\n",
    "    preprocessAllColumns(trainDF, originalTrainDf)\n",
    "    numericAttrs = getNumericAttrs(trainDF)\n",
    "    nonnumericAttrs = getNonNumericAttrs(trainDF)\n",
    "#     print(\"Attributes with missing values:\", getAttrsWithMissingValues(trainDF), sep='\\n')\n",
    "#     print(\"Numeric attributes:\", numericAttrs)\n",
    "#     print(\"Non-numeric attributes:\", nonnumericAttrs)\n",
    "    possibleAttrs = list(numericAttrs)\n",
    "    possibleAttrs.remove('Id')\n",
    "    possibleAttrs.remove('SalePrice')\n",
    "    trainDF.loc[:, possibleAttrs] = standardize(trainDF, trainDF, possibleAttrs)\n",
    "    predictors = ['OverallQual']\n",
    "    possibleAttrs.remove('OverallQual')\n",
    "    i = 0\n",
    "    maxScore = -1\n",
    "    maxAttr = ''\n",
    "#     alg = Ridge(alpha=0.5)\n",
    "    alg = TweedieRegressor(power=1, alpha=0.5, link='log')\n",
    "#     alg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,\n",
    "#                                     max_depth=1, random_state=0, loss='ls')\n",
    "    while i < 15:\n",
    "        for attr in possibleAttrs:\n",
    "            tmp_predictors = predictors.copy()\n",
    "            tmp_predictors.append(attr)       \n",
    "            trainInput = trainDF\n",
    "            trainOutput = trainDF.loc[:, 'SalePrice']\n",
    "            score = doExperiment(trainInput, trainOutput, tmp_predictors, alg)\n",
    "            if score > maxScore:\n",
    "                maxScore = score\n",
    "                maxAttr = attr\n",
    "        predictors.append(maxAttr)\n",
    "        possibleAttrs.remove(maxAttr)\n",
    "        print(f'{predictors}: {maxScore}')\n",
    "        i += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a166fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "def GBR():\n",
    "    trainDF = pd.read_csv(\"data/train.csv\")\n",
    "    originalTrainDf = trainDF.copy()\n",
    "    preprocessAllColumns(trainDF, originalTrainDf)\n",
    "#     numericAttrs = getNumericAttrs(trainDF)\n",
    "#     nonnumericAttrs = getNonNumericAttrs(trainDF)\n",
    "#     possibleAttrs = list(numericAttrs)\n",
    "#     possibleAttrs.remove('Id')\n",
    "#     possibleAttrs.remove('SalePrice')\n",
    "    possibleAttrs = ['OverallQual', 'GrLivArea', '2ndFlrSF', 'BsmtFinSF1', 'YearsOld', 'LotArea', 'TotalBsmtSF', 'BsmtQual', 'OverallCond', 'GarageCars', 'FireplaceQu', 'KitchenQual', 'ScreenPorch']\n",
    "    trainDF.loc[:, possibleAttrs] = standardize(trainDF, trainDF, possibleAttrs)\n",
    "    X, y = trainDF.loc[:, possibleAttrs], trainDF.loc[:, 'SalePrice']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=17)\n",
    "    params = {'n_estimators': 500,\n",
    "              'max_depth': 4,\n",
    "              'min_samples_split': 5,\n",
    "              'learning_rate': 0.01,\n",
    "              'loss': 'ls'}\n",
    "    alg = GradientBoostingRegressor(**params)\n",
    "\n",
    "    trainInput = trainDF.loc[:, possibleAttrs]\n",
    "    trainOutput = trainDF.loc[:, 'SalePrice']\n",
    "    score = doExperiment(trainInput, trainOutput, possibleAttrs, alg)\n",
    "    print(f\"Score is: {score}\")\n",
    "    #     print(getAttrsWithMissingValues(trainInput))\n",
    "    #     print(getNonNumericAttrs(trainInput))\n",
    "    \n",
    "    alg.fit(X_train, y_train)\n",
    "    mse = mean_squared_error(y_test, alg.predict(X_test))\n",
    "    print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "    test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "    for i, y_pred in enumerate(alg.staged_predict(X_test)):\n",
    "        test_score[i] = alg.loss_(y_test, y_pred)\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title('Deviance')\n",
    "    plt.plot(np.arange(params['n_estimators']) + 1, alg.train_score_, 'b-',\n",
    "             label='Training Set Deviance')\n",
    "    plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "             label='Test Set Deviance')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Boosting Iterations')\n",
    "    plt.ylabel('Deviance')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    feature_importance = alg.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, np.array(possibleAttrs)[sorted_idx])\n",
    "    plt.title('Feature Importance (MDI)')\n",
    "\n",
    "    result = permutation_importance(alg, X_test, y_test, n_repeats=10,\n",
    "                                    random_state=42, n_jobs=2)\n",
    "    sorted_idx = result.importances_mean.argsort()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(result.importances[sorted_idx].T,\n",
    "                vert=False, labels=np.array(possibleAttrs)[sorted_idx])\n",
    "    plt.title(\"Permutation Importance (test set)\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# GBR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6be5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "def ensemble_selection():\n",
    "    trainDF = pd.read_csv(\"data/train.csv\")\n",
    "    originalTrainDf = trainDF.copy()\n",
    "    preprocessAllColumns(trainDF, originalTrainDf)\n",
    "    numericAttrs = getNumericAttrs(trainDF)\n",
    "    nonnumericAttrs = getNonNumericAttrs(trainDF)\n",
    "    possibleAttrs = list(numericAttrs)\n",
    "    possibleAttrs.remove('Id')\n",
    "    possibleAttrs.remove('SalePrice')\n",
    "    print(f'Candidate Attributes: {possibleAttrs}')\n",
    "    breakpoint()\n",
    "    trainDF.loc[:, possibleAttrs] = standardize(trainDF, trainDF, possibleAttrs)\n",
    "    params = {'n_estimators': 200,\n",
    "              'max_depth': 4,\n",
    "              'min_samples_split': 5,\n",
    "              'learning_rate': 0.01,\n",
    "              'loss': 'ls'}\n",
    "    alg = GradientBoostingRegressor(**params)\n",
    "    predictors = ['OverallQual']\n",
    "    possibleAttrs.remove('OverallQual')\n",
    "    i = 0\n",
    "    maxScore = -1\n",
    "    maxAttr = ''\n",
    "    while i < 15:\n",
    "        for attr in possibleAttrs:\n",
    "            tmp_predictors = predictors.copy()\n",
    "            tmp_predictors.append(attr)       \n",
    "            trainInput = trainDF\n",
    "            trainOutput = trainDF.loc[:, 'SalePrice']\n",
    "            score = doExperiment(trainInput, trainOutput, tmp_predictors, alg)\n",
    "            if score > maxScore:\n",
    "                maxScore = score\n",
    "                maxAttr = attr\n",
    "        predictors.append(maxAttr)\n",
    "        possibleAttrs.remove(maxAttr)\n",
    "        print(f'{predictors}: {maxScore}')\n",
    "        i += 1;\n",
    "\n",
    "\n",
    "        # ensemble_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.loc[:, 'SalePrice'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18beca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistOfSalePrice(df):\n",
    "    salePrices = df.loc[:, 'SalePrice']\n",
    "    print(salePrices.describe())\n",
    "    # salePrices.hist(bins=50)\n",
    "    sns.distplot(salePrices, fit=stats.norm)\n",
    "plotHistOfSalePrice(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb092f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot overallqual/saleprice\n",
    "var = 'OverallQual'\n",
    "data = pd.concat([trainDF['SalePrice'], trainDF[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"SalePrice\", data=data)\n",
    "fig.axis(ymin=0, ymax=800000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6147f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkCorr(df, k=10):\n",
    "    # BEGIN: from from https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "    # EXPLANATION: Visualization of correlation between SalePrice and k highly correlated elements\n",
    "    corrmat = df.corr().abs()  # ADDED (.abs())\n",
    "    color = plt.get_cmap('RdPu')  # ADDED\n",
    "        \n",
    "#     f, ax = plt.subplots(figsize=(12, 9))\n",
    "#     sns.set(font_scale=0.7)\n",
    "#     sns.heatmap(corrmat, cmap=\"RdPu\", vmax=.8, square=True);\n",
    "#     plt.show()\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(12, 9))\n",
    "    cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "    cm = np.corrcoef(df[cols].values.T)\n",
    "    sns.set(font_scale=1.0)\n",
    "    hm = sns.heatmap(cm, cmap=color, cbar=True, annot=True, square=True, \n",
    "                     fmt='.2f', annot_kws={'size': 10}, vmin=0.2, vmax=0.8,\n",
    "                     yticklabels=cols.values, xticklabels=cols.values)\n",
    "    plt.show()\n",
    "    # END: from https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkCorr(trainDF, k=11)\n",
    "\n",
    "pre_df = trainDF.copy()\n",
    "preprocessAllColumns(pre_df, trainDF)\n",
    "checkCorr(pre_df, k=16)\n",
    "\n",
    "# std_df = standardize(pre_df, pre_df)\n",
    "# checkCorr(std_df, k=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcec61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplots(df):\n",
    "    sns.set()\n",
    "    sns.pairplot(df, height = 2.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da052a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"SalePrice\", \"OverallQual\", \"GrLivArea\", \"ExterQual\", \"KitchenQual\", \"GarageCars\", \"BsmtQual\", \"1stFlrSF\", \"FullBath\", \"GarageFinish\", \"YearsOld\"]\n",
    "pairplots(pre_df.loc[:, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e9e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMissingValues(df):\n",
    "    # BEGIN: from from https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "    # EXPLANATION: Caclulate the number and percentage of missing values and diplay\n",
    "    total = df.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    print(missing_data.head(20))\n",
    "    # END: from from https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82430841",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkMissingValues(trainDF)\n",
    "checkMissingValues(testDF)\n",
    "checkMissingValues(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b3fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNormality(df, col):\n",
    "    # BEGIN: from from https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "    # EXPLANATION: Displays histogram and normal probability plot\n",
    "    sns.distplot(df[col], fit=norm)\n",
    "    fig = plt.figure()\n",
    "    res = stats.probplot(df[col], plot=plt)\n",
    "    # END: from from https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1f90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logTransformation(df):\n",
    "    # BEGIN: from from https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python\n",
    "    # EXPLANATION: Log transformation\n",
    "    df['LogSalePrice'] = np.log(df['SalePrice'])\n",
    "    df['LogGrLivArea'] = np.log(df['GrLivArea'])\n",
    "    # END: from from https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ba62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkNormality(trainDF, 'SalePrice')\n",
    "checkNormality(trainDF, 'GrLivArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logTransformation(trainDF)\n",
    "# checkNormality(trainDF, 'LogSalePrice')\n",
    "checkNormality(trainDF, 'LogGrLivArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee10db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(trainDF['LogGrLivArea'], trainDF['LogSalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCorr(df, col1, col2):\n",
    "    return df.loc[:, col1].corr(df.loc[:, col2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573b9713",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcCorr(trainDF, 'LogSalePrice', 'LogGrLivArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1f11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
